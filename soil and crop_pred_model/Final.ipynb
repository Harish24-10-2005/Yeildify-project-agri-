{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a3b82a5-1b78-4ffa-9c06-270131252e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HARISH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HARISH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the path of the Image: Soil_type_dataset/test_dataset/doubled_output/08.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class for the input image is: black Soil\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.models as models\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "cnn_model = models.densenet121(pretrained=False) \n",
    "cnn_model.classifier = nn.Linear(cnn_model.classifier.in_features, 10)\n",
    "cnn_model.load_state_dict(torch.load('soil_type_pred.pth')) \n",
    "cnn_model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=3),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "image_path = input(\"Enter the path of the Image:\") \n",
    "image = Image.open(image_path)\n",
    "image = transform(image)\n",
    "image = image.unsqueeze(0) \n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    output = cnn_model(image)\n",
    "    probabilities = torch.softmax(output, dim=1)\n",
    "    predicted_class_index = torch.argmax(probabilities, dim=1).item()\n",
    "\n",
    "labels_list = [\n",
    "    \"Alluvial soil\", \"Cinder Soil\", \"Clayey soils\", \"Laterite soil\", \n",
    "    \"Loamy soil\", \"Peat Soil\", \"Sandy loam\", \"Sandy soil\", \n",
    "    \"Yellow Soil\", \"black Soil\"\n",
    "]\n",
    "\n",
    "class_label = labels_list[predicted_class_index]\n",
    "\n",
    "print(f\"The predicted class for the input image is: {class_label}\")\n",
    "# Soil_type_dataset/test_dataset/doubled_output/08.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82868a01-9210-48c4-afac-e640fcc65b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_for_soil = {\"Alluvial soil\":[5,60,2,7.5],\n",
    "                   \"Cinder Soil\":[35,90,25,6.5],\n",
    "                   \"Clayey soils\":[28,250,70,7],\n",
    "                   \"Laterite soil\":[40,25,40,5.6],\n",
    "                   \"Loamy soil\":[90,150,60,4.2],\n",
    "                   \"Peat Soil\":[56,5,10,4.5],\n",
    "                   \"Sandy loam\":[70,32,80,3],\n",
    "                   \"Sandy soil\":[150,143,77,5.3],\n",
    "                   \"Yellow Soil\":[80,20,120,6],\n",
    "                   \"black Soil\":[40,120,60,8]}\n",
    "N = values_for_soil[class_label][0]\n",
    "P=values_for_soil[class_label][1]\n",
    "K=values_for_soil[class_label][2]\n",
    "pH=values_for_soil[class_label][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37af79c8-2b48-4be7-988f-9fe220c286ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the City Name: neyveli\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Crop Recommendation->1: banana\n",
      "Predicted Crop Recommendation->2: banana\n",
      "Predicted Crop Recommendation->3: banana\n"
     ]
    }
   ],
   "source": [
    "from crop import crop_pred\n",
    "crop_instance = crop_pred()\n",
    "city = input(\"Enter the City Name:\")\n",
    "crop_instance.crop_pr(N, P, K, pH, city)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cf1a9a-1e97-40ee-8d19-86fe081cbd18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
