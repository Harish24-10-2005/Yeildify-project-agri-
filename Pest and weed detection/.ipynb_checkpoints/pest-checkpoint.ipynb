{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d03d5b1-1b78-4d79-aeab-004f1a50b6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "494138c6-dd32-4e37-a0df-b6e5d8d2d4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HARISH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HARISH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loop\n",
      "loop 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/6: 100%|██████████████████████████████████████████████████████████████████| 407/407 [02:47<00:00,  2.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/6], Loss: 1.6321, Time: 167.14 seconds\n",
      "loop 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/6: 100%|██████████████████████████████████████████████████████████████████| 407/407 [02:45<00:00,  2.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/6], Loss: 1.0020, Time: 165.53 seconds\n",
      "loop 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/6: 100%|██████████████████████████████████████████████████████████████████| 407/407 [02:42<00:00,  2.51batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/6], Loss: 0.7244, Time: 162.15 seconds\n",
      "loop 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/6: 100%|██████████████████████████████████████████████████████████████████| 407/407 [02:48<00:00,  2.42batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/6], Loss: 0.5875, Time: 168.14 seconds\n",
      "loop 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/6: 100%|██████████████████████████████████████████████████████████████████| 407/407 [02:43<00:00,  2.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/6], Loss: 0.4946, Time: 163.35 seconds\n",
      "loop 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/6: 100%|██████████████████████████████████████████████████████████████████| 407/407 [02:09<00:00,  3.13batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/6], Loss: 0.4317, Time: 129.94 seconds\n",
      "Test Accuracy: 75.43%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Define transformations for preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to fit pretrained model input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))  # Normalize using ImageNet mean and std\n",
    "])\n",
    "\n",
    "# Load your dataset\n",
    "train_data_path = \"pest_insect_dataset/train\"\n",
    "test_data_path = \"pest_insect_dataset/test\"\n",
    "\n",
    "train_dataset = ImageFolder(train_data_path, transform=transform)\n",
    "test_dataset = ImageFolder(test_data_path, transform=transform)\n",
    "\n",
    "# Define DataLoader for your dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Load a pretrained CNN model (DenseNet) and move it to GPU if available\n",
    "cnn_model = models.densenet121(pretrained=True)\n",
    "cnn_model = cnn_model.to(device)\n",
    "\n",
    "# Modify the final fully connected layer for your specific classification task\n",
    "num_classes = len(train_dataset.classes)\n",
    "cnn_model.classifier = nn.Linear(cnn_model.classifier.in_features, num_classes).to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "cnn_model.eval()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "\n",
    "print('Training loop')\n",
    "num_epochs = 6\n",
    "for epoch in range(num_epochs):\n",
    "    cnn_model.train()\n",
    "    running_loss = 0.0\n",
    "    start_time = time.time()  # Start timing for the epoch\n",
    "    print(\"loop 1\")\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move data to the same device as the model\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    end_time = time.time()  # End timing for the epoch\n",
    "    epoch_time = end_time - start_time\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Time: {epoch_time:.2f} seconds\")\n",
    "\n",
    "# Evaluation\n",
    "cnn_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move data to the same device as the model\n",
    "        outputs = cnn_model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcde5a6e-c8a6-4fe4-91bf-c1251ff89ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ants', 'aphids', 'armyworm', 'bees', 'beetle', 'bollworm', 'catterpillar', 'earthworms', 'earwig', 'grasshopper', 'mites', 'mosquito', 'moth', 'sawfly', 'slug', 'snail', 'stem_borer', 'wasp', 'weevil']\n",
      "Predicted label: wasp\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# torch.save(cnn_model.state_dict(), 'cnn_model.pth')\n",
    "\n",
    "# Load the model architecture and state dictionary\n",
    "loaded_model = models.densenet121(pretrained=False)  # Make sure to initialize the same architecture\n",
    "loaded_model.classifier = nn.Linear(loaded_model.classifier.in_features, num_classes)  # Update classifier\n",
    "loaded_model.load_state_dict(torch.load('cnn_model.pth'))\n",
    "loaded_model = loaded_model.to(device)\n",
    "loaded_model.eval()\n",
    "\n",
    "# Now, you can use this loaded model for inference without new training\n",
    "# Assuming you have a single image for prediction\n",
    "# First, you need to preprocess the image similarly as you did during training\n",
    "# Then, you can feed it to the loaded model for prediction\n",
    "\n",
    "# Example of predicting on a single image\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Define the transformation for the single image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# Load the image\n",
    "image_path = \"pest_insect_dataset/test/wasp/wasp (550).jpg\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Apply the transformation\n",
    "input_image = transform(image).unsqueeze(0).to(device)  # Add a batch dimension and move to device\n",
    "\n",
    "# Perform prediction\n",
    "with torch.no_grad():\n",
    "    output = loaded_model(input_image)\n",
    "    _, predicted_class = torch.max(output, 1)\n",
    "\n",
    "predicted_label = train_dataset.classes[predicted_class.item()]\n",
    "print(train_dataset.classes)\n",
    "print(\"Predicted label:\", predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3119d584-3e29-4988-8a74-6db5458bc746",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
